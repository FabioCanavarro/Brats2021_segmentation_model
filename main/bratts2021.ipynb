{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2542390,"sourceType":"datasetVersion","datasetId":1541666}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-01T13:48:42.514824Z","iopub.execute_input":"2024-07-01T13:48:42.516719Z","iopub.status.idle":"2024-07-01T13:48:42.998519Z","shell.execute_reply.started":"2024-07-01T13:48:42.516664Z","shell.execute_reply":"2024-07-01T13:48:42.997449Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/BraTS2021_00495.tar\n/kaggle/input/BraTS2021_Training_Data.tar\n/kaggle/input/BraTS2021_00621.tar\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\n# detect and init the TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n    # instantiate a distribution strategy\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)\nexcept:\n    pass\n%pip install glob\n%pip install nibabel","metadata":{"execution":{"iopub.status.busy":"2024-07-01T13:49:15.990881Z","iopub.execute_input":"2024-07-01T13:49:15.991470Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2024-07-01 13:49:18.055237: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-01 13:49:18.055396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-01 13:49:18.204022: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport tarfile\nfile = tarfile.open('/kaggle/input/BraTS2021_Training_Data.tar')\n\nfile.extractall('./BraTS2021_Training_Data')\nfile.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all messages are logged (default behavior)\n                                          # 1 = INFO messages are not printed\n                                          # 2 = INFO and WARNING messages are not printed\n                                          # 3 = INFO, WARNING, and ERROR messages are not printed\nimport tensorflow as tf\ntf.config.run_functions_eagerly(False)\ntf.get_logger().setLevel('ERROR')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tensorflow.keras as kr\nimport nibabel as nib\nimport numpy as np\nimport os\nfrom glob import glob\nimport matplotlib.pylab as plt\n\nfolder_path = [os.path.join(r\"BraTS2021_Training_Data\", i) for i in os.listdir(r\"BraTS2021_Training_Data\")]\nimgs = []\n\n\nfor i in folder_path:\n    imgs.append(glob(i+\"/*\"))\nprint(\"Done\")\nfolder_path = folder_path[1:]\nimgs = imgs[1:]\nprint(imgs[0])\n\n\n\n#input directory and output directory\noutputpath = []\ninputpath = []\nfor j in imgs:\n    for i in j:\n        if \"seg.nii.gz\" in i.split(\"_\"):\n            outputpath.append(i)\nfor j in imgs:\n    temppath = []\n    for i in j:\n        if \"seg.nii.gz\" not in i.split(\"_\"):\n            temppath.append(i)\n    inputpath.append(temppath)\n    \nx_train_path = inputpath[:1126].copy()\ny_train_path = outputpath[:1126].copy()\nx_eval_path = inputpath[1126:1189].copy()\ny_eval_path = outputpath[1126:1189].copy()\nx_test_path = inputpath[1189:].copy()\ny_test_path = outputpath[1189:].copy()  \n\nparition = {\"train\": x_train_path, \"validation\": x_eval_path}\nlabel = {\"train\": y_train_path, \"validation\": y_eval_path}\n#---------------------------------------------------------------------------------------------------------------------------------------------------------------\n#-----------------------------------------------------------------------------OLD-------------------------------------------------------------------------------\n# def prepoutput():\n#     index = 0\n#     outputimg = np.array((nib.load(outputpath[0]).get_fdata().astype(np.float32)[:, :, 75]))\n#     outputimg = np.expand_dims(outputimg, axis=2)\n#     outputimg = tf.image.resize(outputimg, (256, 256))\n#     for i in range(1,len(outputpath)):\n#         index+=1\n#         print(index)\n#         x = nib.load(outputpath[i]).get_fdata().astype(np.float32)[:, :, 75]\n#         x = np.expand_dims(x, axis=2)\n#         x = tf.image.resize(x, (256, 256))\n#         outputimg = np.dstack((outputimg,x),)\n#     return outputimg\n# outputimg = prepoutput()\n# outputimg = outputimg.transpose((2, 0, 1))\n# np.save('output_dataset.npy', outputimg)\n\n#\n\n\n# inputimg = nib.load(inputpath[0][0]).get_fdata().astype(np.float32)[:, :, 75]\n# for i in range(1,len(inputpath[0])):\n#     inputimg = np.dstack((inputimg,nib.load(inputpath[0][i]).get_fdata().astype(np.float32)[:, :, 75]))\n# inputimg = np.expand_dims(inputimg, axis=0)\n\n# for i in range(1,len(inputpath)):\n#     print(i)\n    \n#     temp = nib.load(inputpath[i][0]).get_fdata().astype(np.float32)[:, :, 75]\n#     print(\"\\t1\")\n#     print(f\"\\t{inputpath[i][0]}\")\n#     for channels in range(1,len(inputpath[i])):\n#         print(f\"\\t{channels+1}\")\n#         print(f\"\\t{inputpath[i][channels]}\")\n#         temp = np.dstack((temp,nib.load(inputpath[i][channels]).get_fdata().astype(np.float32)[:, :, 75]))\n        \n#     temp = np.expand_dims(temp, axis=0)\n#     inputimg = np.concatenate((inputimg,temp), axis=0)\n#     print(inputimg.shape)\n#---------------------------------------------------------------------------------------------------------------------------------------------------------------\n#---------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nimport numpy as np\nimport keras\nimport random\nimport time\nimport os\nimport nibabel as nib\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(240,240,140), n_channels=4,\n                 n_classes=10, shuffle=True, real_batchsize_custom=2, frames_chunk=18,\n                 y_VolSlice_start=0, y_VolSlice_end=None):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.real_batchsize_custom = real_batchsize_custom\n        self.frames_chunk = frames_chunk\n        self.y_VolSlice_start = y_VolSlice_start\n        self.y_VolSlice_end = y_VolSlice_end if y_VolSlice_end is not None else dim[2]\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        sliced_dim = (self.dim[0], self.dim[1], self.y_VolSlice_end - self.y_VolSlice_start)\n        X = np.empty((self.real_batchsize_custom, *sliced_dim, 4))\n        y = np.empty((self.real_batchsize_custom,*sliced_dim, 4), dtype=float)\n\n        initial_point = 0\n        final_point = self.frames_chunk\n        for x in range(self.real_batchsize_custom):    \n            indexes_orig = indexes[initial_point:final_point]\n            list_IDs_temp = [self.list_IDs[k] for k in indexes_orig]\n            X_in, y_in = self.__data_generation(list_IDs_temp)\n            X[x] = X_in\n            y[x] = y_in\n            initial_point = final_point\n            final_point = final_point + self.frames_chunk   \n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples'\n        sliced_dim = (self.dim[0], self.dim[1], self.y_VolSlice_end - self.y_VolSlice_start)\n        X = np.empty((1, *sliced_dim, 4))\n        y = np.zeros((1,*sliced_dim,4))\n        \n        random.seed(time.time())\n\n        for i, file_paths in enumerate(list_IDs_temp):\n            image = self.load_nifti(file_paths)\n                \n\n            X[0] = image\n            \n            \n            # Set the label\n            seg = nib.load(self.labels[i]).get_fdata().astype(np.float16)[:,:,self.y_VolSlice_start:self.y_VolSlice_end]\n            seg[seg==4] = 3\n\n            re= np.expand_dims(seg, axis=0)\n\n            re = tf.image.resize(re,(156,156))\n            re = re[0]\n            seg = tf.cast(re, tf.int32)\n            print(i)\n            mask = tf.one_hot(seg, 4);\n            \n            \n            y[0] = mask\n            \n        X = X.astype(np.float16)\n        y = y.astype(np.float16)\n        \n        return X/np.max(X), Y, y[0]\n\n    def load_nifti(self, file_paths):\n        i = 0\n        temp = nib.load(inputpath[i][0]).get_fdata().astype(np.float16)[:,:,self.y_VolSlice_start:self.y_VolSlice_end]\n        re= np.expand_dims(temp, axis=0)\n        re = tf.image.resize(re,(156,156))\n        temp = re[0]\n        \n        temp = np.expand_dims(temp, axis=3)\n        for channels in range(1,len(file_paths)):\n            tempo = nib.load(file_paths[channels]).get_fdata().astype(np.float16)[:,:,self.y_VolSlice_start:self.y_VolSlice_end]\n            re= np.expand_dims(tempo, axis=0)\n            re = tf.image.resize(re,(156,156))\n            tempo = re[0]\n            tempo = np.expand_dims(tempo, axis=3)\n            temp = np.concatenate((temp,tempo),axis=3)\n        \n        return temp\n\n\nimport tensorflow.keras as keras\nimport numpy as np\nimport matplotlib.pylab as plt\nimport tensorflow as tf\n#set up var\nx_VolSlice_start = 10\nx_VolSlice_end = 150\n\ny_VolSlice_start = 10\ny_VolSlice_end = 150\n\n# x_train = inputimg[:1126].copy()\n# y_train = outputimg[:1126].copy()\n# x_train.shape[0] == y_train.shape[0]\n# x_eval = inputimg[1126:1189].copy()\n# y_eval = outputimg[1126:1189].copy()\n# print(x_eval.shape, y_eval.shape)\n# print(x_eval.shape[0] == y_eval.shape[0])\n# x_test = inputimg[1189:].copy()\n# y_test = outputimg[1189:].copy()\n\n# print(\"train target:\",y_train.shape,\"                test target:\",y_test.shape)\n# print(f\"train x{x_test.shape}\",\"                test x:\", x_test.shape)\n\n# #shuffle data\n# np.random.seed(0)\n# np.random.shuffle(x_train)\n# np.random.shuffle(y_train)\n# np.random.shuffle(x_eval)\n# np.random.shuffle(y_eval)\n\n# np.random.shuffle(x_test)\n# np.random.shuffle(y_test)\n\n# y_train = y_train.astype(int)\n# y_eval = y_eval.astype(int)\n# y_test = y_test.astype(int)\n\n\n# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# import numpy as np\n\n# input_shape = (240, 240, 4)\n# num_classes = 4\n\n# # Data preparation functions\n# #why my last code didnt work:\n# #the labels in the output goes 0,1,2,4????????\n# #yeah 0,1,2,4 not 0,1,2,3 but 0,1,2,4\n# #no wonder i am now depressed\n\n# #side note: np.unique(tells us all unique element)\n# def correct_labels(y):\n#     y[y == 4] = 3\n#     return y\n# #normalize data\n# def normalize_data(x):\n#     return (x - np.min(x)) / (np.max(x) - np.min(x))\n\n# # Apply corrections to your data\n# x_train = normalize_data(x_train)\n# x_eval = normalize_data(x_eval)\n# x_test = normalize_data(x_test)\n\n# y_train = correct_labels(y_train)\n# y_eval = correct_labels(y_eval)\n# y_test = correct_labels(y_test)\n\n# Rest of your code remains the same\n# from keras import layers\n# def unet_model(input_shape, num_classes):\n#     inputs = keras.Input(input_shape)\n    \n#     # Encoder (downsampling)\n#     conv1 = conv_block(inputs, 64)\n#     pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n    \n#     conv2 = conv_block(pool1, 128)\n#     pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n#     conv3 = conv_block(pool2, 256)\n#     pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n    \n#     # Bridge\n#     conv4 = conv_block(pool3, 512)\n    \n#     # Decoder (upsampling)\n#     up5 = layers.UpSampling2D(size=(2, 2))(conv4)\n#     up5 = layers.concatenate([up5, conv3])\n#     conv5 = conv_block(up5, 256)\n    \n#     up6 = layers.UpSampling2D(size=(2, 2))(conv5)\n#     up6 = layers.concatenate([up6, conv2])\n#     conv6 = conv_block(up6, 128)\n    \n#     up7 = layers.UpSampling2D(size=(2, 2))(conv6)\n#     up7 = layers.concatenate([up7, conv1])\n#     conv7 = conv_block(up7, 64)\n    \n#     # Output layer\n#     outputs = layers.Conv2D(num_classes, 1, activation='softmax')(conv7)\n    \n#     return keras.Model(inputs=inputs, outputs=outputs)\n    \n\n# def conv_block(input_tensor, num_filters):\n#     x = layers.Conv2D(num_filters, 3, padding='same')(input_tensor)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     x = layers.Dropout(0.1)(x)\n    \n#     x = layers.Conv2D(num_filters, 3, padding='same')(x)\n#     x = layers.BatchNormalization()(x)\n#     x = layers.Activation('relu')(x)\n#     return x\n\n# model = unet_model(input_shape, num_classes)\n\n# optimizer = keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0)\n# model.compile(optimizer=optimizer, \n#               loss='categorical_crossentropy', \n#               metrics=['accuracy'])\n\n# # Print model summary\n# model.summary()\n#\n\n\n\n\n#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n#---------------------------------------------------------------------model making--------------------------------------------------------------------------------\n\n#note:\n# conv3d need a 5d tensor (height,width,depth,channels)\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model, Droput\n# dice loss as defined above for 4 classes\ndef dice_coef(y_true, y_pred, smooth=1.0):\n    class_num = 4\n    for i in range(class_num):\n        y_true_f = K.flatten(y_true[:,:,:,i])\n        y_pred_f = K.flatten(y_pred[:,:,:,i])\n        intersection = K.sum(y_true_f * y_pred_f)\n        loss = ((2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth))\n   #     K.print_tensor(loss, message='loss value for class {} : '.format(SEGMENT_CLASSES[i]))\n        if i == 0:\n            total_loss = loss\n        else:\n            total_loss = total_loss + loss\n            \n    total_loss = total_loss / class_num\n#    K.print_tensor(total_loss, message=' total dice coef: ')\n    return total_loss\n\n\n \n# These functions are used for evaluating the performance of a segmentation model on three different classes\n# in medical imaging (presumably related to brain tumor segmentation).\n# Input Parameters:\n# y_true: The ground truth segmentation mask for the edema class.\n# y_pred: The predicted segmentation mask for the edema class.\n# epsilon: A small constant to avoid division by zero.\n\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n\n\n# Computing Precision \ndef precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    \n# Computing Sensitivity      \ndef sensitivity(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\n\n# Computing Specificity\ndef specificity(y_true, y_pred):\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())\nfrom tensorflow.keras.layers import Conv2D,Input, MaxPooling2D, concatenate\ndef build_unet(inputs, ker_init, dropout):\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv1)\n    \n    pool = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool)\n    conv = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    pool1 = MaxPooling2D(pool_size=(2, 2))(conv)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool1)\n    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv2)\n    \n    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool2)\n    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv3)\n    \n    \n    pool4 = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv5)\n    drop5 = Dropout(dropout)(conv5)\n\n    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(drop5))\n    merge7 = concatenate([conv3,up7], axis = 3)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge7)\n    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv7)\n\n    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv7))\n    merge8 = concatenate([conv2,up8], axis = 3)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge8)\n    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv8)\n\n    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv8))\n    merge9 = concatenate([conv,up9], axis = 3)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge9)\n    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv9)\n    \n    up = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(UpSampling2D(size = (2,2))(conv9))\n    merge = concatenate([conv1,up], axis = 3)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(merge)\n    conv = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = ker_init)(conv)\n    \n    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv)\n    \n    return Model(inputs = inputs, outputs = conv10)\ninput_layer = Input((156, 156, 4))\nimport tensorflow as tf\ntf.keras.backend.clear_session()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"start\")\n\ntry:\n    with tpu_strategy.scope():\n        model = build_unet(input_layer, 'he_normal', 0.2)\n        model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )\n    tf.debugging.set_log_device_placement(True)\nexcept:\n    model = build_unet(input_layer, 'he_normal', 0.2)\n    model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy',tf.keras.metrics.MeanIoU(num_classes=4), dice_coef, precision, sensitivity, specificity, dice_coef_necrotic, dice_coef_edema ,dice_coef_enhancing] )\n    tf.debugging.set_log_device_placement(True)\n    \nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfilepath=\"3D-UNet-2018-weights-improvement-{epoch:02d}-{val_accuracy:.3f}.hdf5\" \n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\ncsv_logger = CSVLogger('training_2021_2D_UNet.log')\n\nhistory =  model.fit(training_generator,\n                    epochs=12,\n                    steps_per_epoch=len(train_ids),\n                    callbacks= [checkpoint, csv_logger, early_stop],\n                    validation_data = valid_generator\n                    )\n\nwith open('history.txt', 'w') as f:\n    f.write(history)\nmodel.save(\"best_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model","metadata":{}},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}