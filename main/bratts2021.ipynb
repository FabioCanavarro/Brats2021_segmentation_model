{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2542390,"sourceType":"datasetVersion","datasetId":1541666}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T13:30:06.772918Z","iopub.execute_input":"2024-07-02T13:30:06.774225Z","iopub.status.idle":"2024-07-02T13:30:06.789112Z","shell.execute_reply.started":"2024-07-02T13:30:06.774182Z","shell.execute_reply":"2024-07-02T13:30:06.787481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# detect and init the TPU\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n    # instantiate a distribution strategy\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.TPUStrategy(tpu)\nexcept:\n    pass\n%pip install glob\n%pip install nibabel","metadata":{"execution":{"iopub.status.busy":"2024-07-02T13:30:06.791176Z","iopub.execute_input":"2024-07-02T13:30:06.791673Z","iopub.status.idle":"2024-07-02T13:30:24.847368Z","shell.execute_reply.started":"2024-07-02T13:30:06.791639Z","shell.execute_reply":"2024-07-02T13:30:24.845550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport tarfile\nfile = tarfile.open('/kaggle/input/BraTS2021_Training_Data.tar')\n\nfile.extractall('./BraTS2021_Training_Data')\nfile.close()\nfrom tensorflow.keras import mixed_precision\n\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)","metadata":{"execution":{"iopub.status.busy":"2024-07-02T13:30:24.851218Z","iopub.execute_input":"2024-07-02T13:30:24.852711Z","iopub.status.idle":"2024-07-02T13:32:43.106901Z","shell.execute_reply.started":"2024-07-02T13:30:24.852655Z","shell.execute_reply":"2024-07-02T13:32:43.104264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0 = all messages are logged (default behavior)\n                                          # 1 = INFO messages are not printed\n                                          # 2 = INFO and WARNING messages are not printed\n                                          # 3 = INFO, WARNING, and ERROR messages are not printed\nimport tensorflow as tf\ntf.config.run_functions_eagerly(False)\ntf.get_logger().setLevel('ERROR')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-02T13:49:59.396880Z","iopub.execute_input":"2024-07-02T13:49:59.400924Z","iopub.status.idle":"2024-07-02T13:49:59.419030Z","shell.execute_reply.started":"2024-07-02T13:49:59.400842Z","shell.execute_reply":"2024-07-02T13:49:59.416943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras as kr\nimport tensorflow.keras as keras\nimport nibabel as nib\nimport numpy as np\nimport os\nfrom glob import glob\nimport matplotlib.pylab as plt\nimport keras\nimport random\nimport time\n\n\n\nfolder_path = [os.path.join(r\"BraTS2021_Training_Data\", i) for i in os.listdir(r\"BraTS2021_Training_Data\")]\nimgs = []\n\n\nfor i in folder_path:\n    imgs.append(glob(i+\"/*\"))\nprint(\"Done\")\nfolder_path = folder_path[1:]\nimgs = imgs[1:]\nprint(imgs[0])\n\n\n\n#input directory and output directory\noutputpath = []\ninputpath = []\nfor j in imgs:\n    for i in j:\n        if \"seg.nii.gz\" in i.split(\"_\"):\n            outputpath.append(i)\nfor j in imgs:\n    temppath = []\n    for i in j:\n        if \"seg.nii.gz\" not in i.split(\"_\"):\n            temppath.append(i)\n    inputpath.append(temppath)\n    \nx_train_path = inputpath[:1126].copy()\ny_train_path = outputpath[:1126].copy()\nx_eval_path = inputpath[1126:1189].copy()\ny_eval_path = outputpath[1126:1189].copy()\nx_test_path = inputpath[1189:].copy()\ny_test_path = outputpath[1189:].copy()  \n\nparition = {\"train\": x_train_path, \"validation\": x_eval_path}\nlabel = {\"train\": y_train_path, \"validation\": y_eval_path}\n\n\n\n#set up var\nx_VolSlice_start = 10\nx_VolSlice_end = 150\n\ny_VolSlice_start = 10\ny_VolSlice_end = 150\n\n\n#-----------------------------------------------------------------------------------------------------------------------------------------------------------------\n#---------------------------------------------------------------------model making--------------------------------------------------------------------------------\n\n\n\nclass GradientAccumulationModel(tf.keras.Model):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.n_gradients = tf.Variable(0, dtype=tf.int32, trainable=False)\n        self.n_acum_steps = tf.Variable(4, dtype=tf.int32, trainable=False)\n        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), trainable=False) for v in self.trainable_variables]\n\n    def train_step(self, data):\n        self.n_gradients.assign_add(1)\n        x, y = data\n        \n        with tf.GradientTape() as tape:\n            y_pred = self(x, training=True)\n            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n        \n        gradients = tape.gradient(loss, self.trainable_variables)\n        \n        for i in range(len(self.gradient_accumulation)):\n            self.gradient_accumulation[i].assign_add(gradients[i])\n        \n        tf.cond(tf.equal(self.n_gradients, self.n_acum_steps), \n                lambda: self.apply_accu_gradients(), \n                lambda: tf.no_op())\n        \n        self.compiled_metrics.update_state(y, y_pred)\n        return {m.name: m.result() for m in self.metrics}\n\n    def apply_accu_gradients(self):\n        self.optimizer.apply_gradients(zip(self.gradient_accumulation, self.trainable_variables))\n        \n        for i in range(len(self.gradient_accumulation)):\n            self.gradient_accumulation[i].assign(tf.zeros_like(self.trainable_variables[i], dtype=tf.float32))\n        \n        self.n_gradients.assign(0)\n\n#note:\n# conv3d need a 5d tensor (height,width,depth,channels)\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\n# dice loss as defined above for 4 classes\ndef dice_coefficient(y_true, y_pred, smooth=1):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    y_true_f = tf.keras.backend.flatten(y_true)\n    y_pred_f = tf.keras.backend.flatten(y_pred)\n    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n\n\n \n# These functions are used for evaluating the performance of a segmentation model on three different classes\n# in medical imaging (presumably related to brain tumor segmentation).\n# Input Parameters:\n# y_true: The ground truth segmentation mask for the edema class.\n# y_pred: The predicted segmentation mask for the edema class.\n# epsilon: A small constant to avoid division by zero.\n\n\nimport tensorflow as tf\nfrom tensorflow import keras\nK = keras.backend\n\ndef dice_coef(y_true, y_pred, smooth=1.):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# Update other metric functions similarly\ndef dice_coef_necrotic(y_true, y_pred, epsilon=1e-6):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    intersection = K.sum(K.abs(y_true[:,:,:,1] * y_pred[:,:,:,1]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,1])) + K.sum(K.square(y_pred[:,:,:,1])) + epsilon)\n\ndef dice_coef_edema(y_true, y_pred, epsilon=1e-6):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    intersection = K.sum(K.abs(y_true[:,:,:,2] * y_pred[:,:,:,2]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,2])) + K.sum(K.square(y_pred[:,:,:,2])) + epsilon)\n\ndef dice_coef_enhancing(y_true, y_pred, epsilon=1e-6):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    intersection = K.sum(K.abs(y_true[:,:,:,3] * y_pred[:,:,:,3]))\n    return (2. * intersection) / (K.sum(K.square(y_true[:,:,:,3])) + K.sum(K.square(y_pred[:,:,:,3])) + epsilon)\n\n# Update other metric functions if necessary\ndef precision(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef sensitivity(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    return true_positives / (possible_positives + K.epsilon())\n\ndef specificity(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    true_negatives = K.sum(K.round(K.clip((1-y_true) * (1-y_pred), 0, 1)))\n    possible_negatives = K.sum(K.round(K.clip(1-y_true, 0, 1)))\n    return true_negatives / (possible_negatives + K.epsilon())\n\n\nfrom tensorflow.keras import layers\n\ndef conv_block_3d(input_tensor, num_filters):\n    x = layers.Conv3D(num_filters, 3, padding='same')(input_tensor)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Dropout(0.3)(x)  # Add dropout\n    x = layers.Conv3D(num_filters, 3, padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    return x\n\ndef unet_3d(input_shape=(156, 156, 140, 4), num_classes=4):\n    inputs = layers.Input(input_shape, dtype='float16')\n    \n    # Encoder (downsampling)\n    conv1 = conv_block_3d(inputs, 32)\n    pool1 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n    \n    conv2 = conv_block_3d(pool1, 64)\n    pool2 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n    \n    conv3 = conv_block_3d(pool2, 128)\n    pool3 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv3)\n    \n    conv4 = conv_block_3d(pool3, 256)\n    pool4 = layers.MaxPooling3D(pool_size=(2, 2, 2))(conv4)\n    \n    # Bridge\n    conv5 = conv_block_3d(pool4, 512)\n    \n    # Decoder (upsampling)\n    up6 = layers.Conv3DTranspose(256, 2, strides=(2, 2, 2), padding='same')(conv5)\n    up6 = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, conv4.shape[1] - x.shape[1]], [0, conv4.shape[2] - x.shape[2]], [0, conv4.shape[3] - x.shape[3]], [0, 0]]))(up6)\n    concat6 = layers.Concatenate()([up6, conv4])\n    conv6 = conv_block_3d(concat6, 256)\n    \n    up7 = layers.Conv3DTranspose(128, 2, strides=(2, 2, 2), padding='same')(conv6)\n    up7 = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, conv3.shape[1] - x.shape[1]], [0, conv3.shape[2] - x.shape[2]], [0, conv3.shape[3] - x.shape[3]], [0, 0]]))(up7)\n    concat7 = layers.Concatenate()([up7, conv3])\n    conv7 = conv_block_3d(concat7, 128)\n    \n    up8 = layers.Conv3DTranspose(64, 2, strides=(2, 2, 2), padding='same')(conv7)\n    up8 = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, conv2.shape[1] - x.shape[1]], [0, conv2.shape[2] - x.shape[2]], [0, conv2.shape[3] - x.shape[3]], [0, 0]]))(up8)\n    concat8 = layers.Concatenate()([up8, conv2])\n    conv8 = conv_block_3d(concat8, 64)\n    \n    up9 = layers.Conv3DTranspose(32, 2, strides=(2, 2, 2), padding='same')(conv8)\n    up9 = layers.Lambda(lambda x: tf.pad(x, [[0, 0], [0, conv1.shape[1] - x.shape[1]], [0, conv1.shape[2] - x.shape[2]], [0, conv1.shape[3] - x.shape[3]], [0, 0]]))(up9)\n    concat9 = layers.Concatenate()([up9, conv1])\n    conv9 = conv_block_3d(concat9, 32)\n    \n    outputs = layers.Conv3D(num_classes, 1, activation='softmax', dtype='float32')(conv9)\n    \n    model = GradientAccumulationModel(inputs=inputs, outputs=outputs)\n    return model\n\nimport tensorflow as tf\ntf.keras.backend.clear_session()\ndef lr_schedule(epoch):\n    initial_lr = 0.001\n    drop = 0.5\n    epochs_drop = 5.0\n    lr = initial_lr * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n    return lr\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n\n# Add lr_scheduler to your callbacks list when fitting the model\nprint(\"start\")\n\n\ndef weighted_categorical_crossentropy(class_weights):\n    def loss(y_true, y_pred):\n        y_true = tf.cast(y_true, tf.float32)\n        y_pred = tf.cast(y_pred, tf.float32)\n        weighted_losses = y_true * class_weights * tf.math.log(y_pred + 1e-7)\n        return -tf.reduce_sum(weighted_losses, -1)\n    return loss\ndef dice_loss(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1,2,3))\n    denominator = tf.reduce_sum(y_true + y_pred, axis=(1,2,3))\n    return 1 - numerator / denominator\n\ndef combined_loss(y_true, y_pred):\n    class_weights = tf.constant([0.1, 1.0, 1.0, 1.0])\n    wce = weighted_categorical_crossentropy(class_weights)(y_true, y_pred)\n    dice = dice_loss(y_true, y_pred)\n    return wce + dice\n# Example class weights (adjust based on your data)\nclass_weights = tf.constant([0.1, 1.0, 1.0, 1.0])\n\ntry:\n    with tpu_strategy.scope():\n        model = unet_3d(input_shape=(156, 156, 140, 4), num_classes=4)\n        model.compile(loss=combined_loss,\n              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=4),\n                       dice_coef, precision, sensitivity, specificity,\n                       dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing])\n    tf.debugging.set_log_device_placement(True)\nexcept:\n    model = unet_3d(input_shape=(156, 156, 140, 4), num_classes=4)\n    model.compile(loss=weighted_categorical_crossentropy(class_weights),\n              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=4),\n                       dice_coef, precision, sensitivity, specificity,\n                       dice_coef_necrotic, dice_coef_edema, dice_coef_enhancing])\n    tf.debugging.set_log_device_placement(True)\n    \nmodel.summary()\n\n\n\ndef augment(image, mask):\n    # Random flip left-right\n    if tf.random.uniform(()) > 0.5:\n        image = tf.image.flip_left_right(image)\n        mask = tf.image.flip_left_right(mask)\n    \n    # Random flip up-down\n    if tf.random.uniform(()) > 0.5:\n        image = tf.image.flip_up_down(image)\n        mask = tf.image.flip_up_down(mask)\n    \n    # Random rotation\n    angle = tf.random.uniform((), minval=-0.1, maxval=0.1)\n    image = tf.contrib.image.rotate(image, angle)\n    mask = tf.contrib.image.rotate(mask, angle)\n    \n    return image, mask\n\n# In your __data_generation method, after loading and preprocessing:\n\n\n#datagen\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=5, dim=(156,156,140), n_channels=4,\n                 n_classes=10, shuffle=True, real_batchsize_custom=2, frames_chunk=18,\n                 y_VolSlice_start=0, y_VolSlice_end=None):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        self.real_batchsize_custom = real_batchsize_custom\n        self.frames_chunk = frames_chunk\n        self.y_VolSlice_start = y_VolSlice_start\n        self.y_VolSlice_end = y_VolSlice_end if y_VolSlice_end is not None else dim[2]\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        sliced_dim = (self.dim[0], self.dim[1], self.y_VolSlice_end - self.y_VolSlice_start)\n        X = np.empty((self.real_batchsize_custom, *sliced_dim, 4))\n        y = np.empty((self.real_batchsize_custom,*sliced_dim, 4), dtype=float)\n\n        initial_point = 0\n        final_point = self.frames_chunk\n        for x in range(self.real_batchsize_custom):    \n            indexes_orig = indexes[initial_point:final_point]\n            list_IDs_temp = [self.list_IDs[k] for k in indexes_orig]\n            X_in, y_in = self.__data_generation(list_IDs_temp)\n            X[x] = X_in\n            y[x] = y_in\n            initial_point = final_point\n            final_point = final_point + self.frames_chunk   \n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples'\n        sliced_dim = (self.dim[0], self.dim[1], 140)\n        X = np.empty((1, *sliced_dim, 4))\n        y = np.zeros((1,*sliced_dim,4))\n        \n        random.seed(time.time())\n\n        for i, file_paths in enumerate(list_IDs_temp):\n            image = self.load_nifti(file_paths)\n                \n            X[0] = image\n            \n            # Set the label\n            seg = nib.load(self.labels[i]).get_fdata().astype(np.float16)[:,:,self.y_VolSlice_start:self.y_VolSlice_end]\n            seg[seg==4] = 3\n\n            re= np.expand_dims(seg, axis=0)\n\n            re = tf.image.resize(re,(156,156))\n            re = re[0]\n            seg = tf.cast(re, tf.int32)\n            print(i)\n            mask = tf.one_hot(seg, 4)\n            \n            y[0] = mask\n            \n        X = X.astype(np.float16)\n        y = y.astype(np.float16)\n        \n        # Improved normalization\n        X_norm = np.zeros_like(X[0])\n        for c in range(X[0].shape[-1]):  # Iterate over channels\n            channel = X[0][..., c]\n            min_val = np.min(channel)\n            max_val = np.max(channel)\n            if max_val > min_val:\n                X_norm[..., c] = (channel - min_val) / (max_val - min_val)\n            else:\n                X_norm[..., c] = channel  # If max == min, keep original values\n        X_norm, y[0] = self.augment(X_norm, y[0])\n        return X_norm, y[0]\n\n    def load_nifti(self, file_paths):\n        i = 0\n        temp = nib.load(inputpath[i][0]).get_fdata().astype(np.float16)[:,:,self.y_VolSlice_start:self.y_VolSlice_end]\n        re= np.expand_dims(temp, axis=0)\n        re = tf.image.resize(re,(156,156))\n        temp = re[0]\n        \n        temp = np.expand_dims(temp, axis=3)\n        for channels in range(1,len(file_paths)):\n            tempo = nib.load(file_paths[channels]).get_fdata().astype(np.float16)[:,:,self.y_VolSlice_start:self.y_VolSlice_end]\n            re= np.expand_dims(tempo, axis=0)\n            re = tf.image.resize(re,(156,156))\n            tempo = re[0]\n            tempo = np.expand_dims(tempo, axis=3)\n            temp = np.concatenate((temp,tempo),axis=3)\n        \n        return temp\ntraining_generator = DataGenerator(parition[\"train\"],label[\"train\"])\nvalid_generator = DataGenerator(parition[\"validation\"],label[\"validation\"])\n\n#model fitting\n\n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n\nfilepath=\"3D-UNet-2018-weights-improvement-{epoch:02d}-{val_accuracy:.3f}.keras\" \n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n\ncsv_logger = CSVLogger('training_2021_2D_UNet.log')\n\nhistory =  model.fit(training_generator,\n                    epochs=12,\n                    steps_per_epoch=len(parition[\"train\"]),\n                    callbacks= [checkpoint, csv_logger, early_stop, lr_scheduler],\n                    validation_data = valid_generator\n                    )\n\nwith open('history.txt', 'w') as f:\n    f.write(history)\ntry:\n    model.save(\"final_model.h5\")\nexcept:\n    model.save(\"final_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2024-07-02T15:34:58.662898Z","iopub.execute_input":"2024-07-02T15:34:58.663490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model","metadata":{}},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}